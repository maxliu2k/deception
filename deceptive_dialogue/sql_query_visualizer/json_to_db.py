import os
import sys
import json
import sqlite3
import argparse

def get_json_files(folder_path):
    json_files = [os.path.join(folder_path, f) for f in os.listdir(folder_path) if f.endswith('.json') and os.path.isfile(os.path.join(folder_path, f))]
    return sorted(json_files)  # Return files in lexicographical order for consistent processing

def load_all_json_objects(json_files):
    all_objects = []
    for file in json_files:
        with open(file, 'r') as f:
            data = json.load(f)
            if not isinstance(data, list):
                print(f"Error: File {file} does not contain a list of JSON objects.")
                sys.exit(1)
            # Add filename and index to each object
            filename = os.path.basename(file)
            for index, obj in enumerate(data):
                obj['DB_FILENAME'] = filename
                obj['DB_FILENAME_INDEX'] = index
            all_objects.extend(data)
    
    # Add DB_INDEX to each object based on the order they were added
    for db_index, obj in enumerate(all_objects):
        obj['DB_INDEX'] = db_index
    
    return all_objects

def find_common_fields(json_files):
    """Find fields that are present in all JSON files"""
    if not json_files:
        return set()
    
    # Get all unique fields from each file
    all_field_sets = []
    for file_path in json_files:
        with open(file_path, 'r') as f:
            data = json.load(f)
            if not data:
                continue
            # Get fields from the first object (assuming consistent structure within file)
            file_fields = set(data[0].keys())
            all_field_sets.append(file_fields)
    
    if not all_field_sets:
        return set()
    
    # Find intersection of all field sets
    common_fields = all_field_sets[0]
    for field_set in all_field_sets[1:]:
        common_fields = common_fields.intersection(field_set)
    
    return common_fields

def check_field_consistency(objects, json_files, column_order=None):
    if not objects:
        print("No JSON objects found.")
        sys.exit(1)
    
    # Get the lexicographically first JSON file and its first object to determine field order
    sorted_json_files = sorted(json_files)
    first_file = sorted_json_files[0]
    
    with open(first_file, 'r') as f:
        first_file_data = json.load(f)
        if not first_file_data:
            print(f"Error: First file {first_file} is empty.")
            sys.exit(1)
        # Get the field order from the first object of the first file
        first_object_fields = list(first_file_data[0].keys())
    
    # Remove DB_FILENAME, DB_FILENAME_INDEX, and DB_INDEX from consistency check since they're added automatically
    first_fields = set(first_object_fields) - {'DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX'}
    inconsistencies = []
    
    # Track which file each object came from
    object_index = 0
    for file_idx, file_path in enumerate(json_files):
        with open(file_path, 'r') as f:
            data = json.load(f)
            for obj_idx, obj in enumerate(data):
                obj_fields = set(obj.keys()) - {'DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX'}
                if obj_fields != first_fields:
                    filename = os.path.basename(file_path)
                    inconsistencies.append({
                        'filename': filename,
                        'file_index': file_idx,
                        'object_index': object_index,
                        'expected_fields': first_fields,
                        'actual_fields': obj_fields
                    })
                object_index += 1
    
    if inconsistencies:
        print("Error: Inconsistent fields found in the following locations:")
        for inc in inconsistencies:
            print(f"  File: {inc['filename']}, Object index: {inc['object_index']}")
            print(f"    Expected fields: {sorted(inc['expected_fields'])}")
            print(f"    Actual fields: {sorted(inc['actual_fields'])}")
            print()
        
        # Find common fields across all files
        common_fields = find_common_fields(json_files)
        if common_fields:
            print(f"Common fields across all files: {sorted(common_fields)}")
            print()
            response = input("Would you like to create a database with only the common fields? (y/n): ").strip().lower()
            if response in ['y', 'yes']:
                # Return common fields for processing
                common_fields_list = list(common_fields) + ['DB_FILENAME']
                return common_fields_list, True  # True indicates we're using common fields
            else:
                print("Operation cancelled.")
                sys.exit(1)
        else:
            print("No common fields found across all files. Cannot proceed.")
            sys.exit(1)
    
    # Handle column ordering
    if column_order:
        # Check if DB_FILENAME, DB_FILENAME_INDEX, and DB_INDEX are specified in the column order
        db_filename_in_order = 'DB_FILENAME' in column_order
        db_filename_index_in_order = 'DB_FILENAME_INDEX' in column_order
        db_index_in_order = 'DB_INDEX' in column_order
        
        # Validate that all specified columns exist in the data (excluding DB_FILENAME, DB_FILENAME_INDEX, and DB_INDEX)
        available_fields = list(first_fields)
        missing_fields = [field for field in column_order if field not in available_fields and field not in ['DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX']]
        if missing_fields:
            print(f"Error: The following columns specified in --column-order do not exist in the data: {missing_fields}")
            print(f"Available columns: {available_fields}")
            sys.exit(1)
        
        # Determine which automatic fields are specified and which need to be added
        specified_auto_fields = []
        if db_filename_in_order:
            specified_auto_fields.append('DB_FILENAME')
        if db_filename_index_in_order:
            specified_auto_fields.append('DB_FILENAME_INDEX')
        if db_index_in_order:
            specified_auto_fields.append('DB_INDEX')
        
        if len(specified_auto_fields) == 3:
            # User specified all three automatic fields, use their exact order
            remaining_fields = [field for field in available_fields if field not in column_order]
            fields_list = column_order + remaining_fields
        elif len(specified_auto_fields) == 2:
            # User specified two automatic fields, add the missing one after the last specified one
            remaining_fields = [field for field in available_fields if field not in column_order]
            missing_auto_field = [field for field in ['DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX'] if field not in specified_auto_fields][0]
            last_specified_pos = max(column_order.index(field) for field in specified_auto_fields)
            fields_list = column_order[:last_specified_pos+1] + [missing_auto_field] + column_order[last_specified_pos+1:] + remaining_fields
        elif len(specified_auto_fields) == 1:
            # User specified one automatic field, add the other two after it
            remaining_fields = [field for field in available_fields if field not in column_order]
            missing_auto_fields = [field for field in ['DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX'] if field not in specified_auto_fields]
            specified_pos = column_order.index(specified_auto_fields[0])
            fields_list = column_order[:specified_pos+1] + missing_auto_fields + column_order[specified_pos+1:] + remaining_fields
        else:
            # User didn't specify any, add all three at the end
            remaining_fields = [field for field in available_fields if field not in column_order]
            fields_list = column_order + remaining_fields + ['DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX']
    else:
        # Use the field order from the first object of the lexicographically first file
        # Filter out DB_FILENAME, DB_FILENAME_INDEX, and DB_INDEX if they exist in the original data
        original_field_order = [field for field in first_object_fields if field not in ['DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX']]
        fields_list = original_field_order + ['DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX']
    
    return fields_list, False  # False indicates we're using all fields

def filter_objects_to_common_fields(objects, common_fields):
    """Filter objects to only include common fields"""
    filtered_objects = []
    for obj in objects:
        filtered_obj = {}
        for field in common_fields:
            if field in obj:
                filtered_obj[field] = obj[field]
        # Always include DB_FILENAME, DB_FILENAME_INDEX, and DB_INDEX if they exist in the original object
        if 'DB_FILENAME' in obj:
            filtered_obj['DB_FILENAME'] = obj['DB_FILENAME']
        if 'DB_FILENAME_INDEX' in obj:
            filtered_obj['DB_FILENAME_INDEX'] = obj['DB_FILENAME_INDEX']
        if 'DB_INDEX' in obj:
            filtered_obj['DB_INDEX'] = obj['DB_INDEX']
        filtered_objects.append(filtered_obj)
    return filtered_objects

def detect_column_type(field_name, objects):
    """Detect the appropriate SQLite column type based on the data"""
    # Check if all values for this field are of the same type
    sample_values = [obj[field_name] for obj in objects if obj[field_name] is not None]
    
    if not sample_values:
        return 'TEXT'  # Default to TEXT if no non-null values
    
    # Check if all values are integers
    try:
        all_int = all(isinstance(val, int) or (isinstance(val, str) and val.isdigit()) for val in sample_values)
        if all_int:
            return 'INTEGER'
    except:
        pass
    
    # Check if all values are numbers (float or int)
    try:
        all_numeric = all(isinstance(val, (int, float)) or (isinstance(val, str) and val.replace('.', '').replace('-', '').isdigit()) for val in sample_values)
        if all_numeric:
            return 'REAL'
    except:
        pass
    
    # Default to TEXT for strings or mixed types
    return 'TEXT'

def create_table(cursor, table_name, fields, objects):
    columns = []
    for field in fields:
        col_type = detect_column_type(field, objects)
        columns.append(f'"{field}" {col_type}')
    columns_sql = ', '.join(columns)
    cursor.execute(f'CREATE TABLE IF NOT EXISTS "{table_name}" ({columns_sql});')

def insert_objects(cursor, table_name, fields, objects):
    placeholders = ', '.join(['?' for _ in fields])
    columns = ', '.join([f'"{field}"' for field in fields])
    for obj in objects:
        values = []
        for field in fields:
            value = obj[field]
            # Convert lists, dicts, and other complex types to JSON strings
            if isinstance(value, (list, dict)):
                value = json.dumps(value)
            values.append(value)
        cursor.execute(f'INSERT INTO "{table_name}" ({columns}) VALUES ({placeholders});', values)

def main():
    parser = argparse.ArgumentParser(description='Convert a folder of JSON files to a SQLite database.')
    parser.add_argument('json_folder', type=str, help='Path to folder containing JSON files')
    parser.add_argument('output_db', type=str, help='Path to output SQLite database file')
    parser.add_argument('--table', type=str, default='data', help='Table name (default: data)')
    parser.add_argument('--column-order', nargs='+', help='Specify the order of columns in the table (e.g., --column-order field1 field2 field3)')
    args = parser.parse_args()

    json_files = get_json_files(args.json_folder)
    if not json_files:
        print('No JSON files found in the specified folder.')
        sys.exit(1)

    all_objects = load_all_json_objects(json_files)
    fields, use_common_fields = check_field_consistency(all_objects, json_files, args.column_order)

    if use_common_fields:
        # fields already includes DB_FILENAME, DB_FILENAME_INDEX, and DB_INDEX, but we need to filter without them
        common_fields_without_db = [f for f in fields if f not in ['DB_FILENAME', 'DB_FILENAME_INDEX', 'DB_INDEX']]
        all_objects = filter_objects_to_common_fields(all_objects, common_fields_without_db)
        print(f"Using common fields for database creation. Total records: {len(all_objects)}")
        print(f"Common fields: {', '.join(common_fields_without_db)}")
    else:
        print(f"Using all fields for database creation. Total records: {len(all_objects)}")
        print(f"Field order: {', '.join(fields)}")

    con = sqlite3.connect(args.output_db)
    cur = con.cursor()
    create_table(cur, args.table, fields, all_objects)
    insert_objects(cur, args.table, fields, all_objects)
    con.commit()
    con.close()
    
    print(f'Successfully created database {args.output_db} with table "{args.table}" containing {len(all_objects)} records.')

if __name__ == '__main__':
    main() 