{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "# from dash import Dash, html, dcc, Input, Output, callback\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as go\n",
    "import glob\n",
    "import re\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to Use\n",
    "\n",
    "Add metrics to plot in the function below \\\n",
    "Use grab_exp_run_stats() to grab the particular dataset to plot (exp=None for all exp, sof1=None for all sof1 and sof2) \\\n",
    "Concatenate dfs if you'd like to combine datasets to graph, at the end df1 is plotted \\\n",
    "Might need to install plotly, dash, and update Flask/Werkzeug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_metrics(run):\n",
    "    run['alignment_avg'] = (run['a1_sof_alignment'] + run['a2_sof_alignment']) / 2\n",
    "    run['value_avg'] = (run['a1_value'] + run['a2_value']) / 2\n",
    "    return run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sofs = [\"max\", \"max_sum\", \"max_min\", \"max_prod\", \"min\", \"max_diff\"]\n",
    "\n",
    "def grab_run_stats(model, seed, exp, sof1, sof2, half=False):\n",
    "    h = []\n",
    "    exp_config_file = glob.glob('deal_or_no_deal/config/exp' + str(exp) + '.json')[0]\n",
    "    with open(exp_config_file, 'r') as f:\n",
    "        exp_num = int(re.search('\\d+', exp_config_file).group(0))\n",
    "        config = json.load(f)\n",
    "        chain_of_thought = False\n",
    "        random_point_vals = True\n",
    "        if config['deception']:\n",
    "            deception_text = 'deception'\n",
    "        else:\n",
    "            deception_text = 'no_deception'\n",
    "        same_prompt = not config['hidden_point_vals'] # handle weird conditional entanglement b/w same_prompt and hidden_point_vals\n",
    "        if half:\n",
    "            exp_glob = glob.glob(f\"deal_or_no_deal/exp/{model + '-' + str(seed)}/{config['persuasion_taxonomy']}_{deception_text}_{config['theory_of_mind']}_{model}_{sof1}_{sof2}_{'half'}_{config['sof_visible']}_{chain_of_thought}_{config['hidden_point_vals']}_{random_point_vals}_{same_prompt}.json\")\n",
    "        else:\n",
    "            exp_glob = glob.glob(f\"deal_or_no_deal/exp/{model + '-' + str(seed)}/{config['persuasion_taxonomy']}_{deception_text}_{config['theory_of_mind']}_{model}_{sof1}_{sof2}_{config['sof_visible']}_{chain_of_thought}_{config['hidden_point_vals']}_{random_point_vals}_{same_prompt}.json\")\n",
    "        for exp_json in exp_glob:\n",
    "            with open(exp_json, 'r') as f2:\n",
    "                data = json.load(f2)\n",
    "                max_runs = 10\n",
    "                for run in data:\n",
    "                    if run['valid'] and run['valid_u_post_u_prior'] and not run['decided_no_agreement'] and not run['exceeded_rounds'] and max_runs > 0:\n",
    "                        run['model_seed'] = model + '-' + str(seed)\n",
    "                        run['exp_num'] = 'exp' + str(exp_num)\n",
    "                        max_runs -= 1\n",
    "                        h.append(add_metrics(run))\n",
    "    return h\n",
    "\n",
    "def grab_exp_run_stats(model, seed, sof1=None, sof2='max', exp=None, half=False):\n",
    "    h = []\n",
    "    if exp == None:\n",
    "        for exp in range(11):\n",
    "            if sof1 == None: # print all combos of sofs for all exp\n",
    "                for sf1 in sofs:\n",
    "                    for sf2 in sofs:\n",
    "                        h.extend(grab_run_stats(model, seed, exp, sf1, sf2, half=half))\n",
    "            else: # runs for only one specific sof\n",
    "                h.extend(grab_run_stats(model, seed, exp, sof1, sof2, half=half))\n",
    "    else:\n",
    "        if sof1 == None: # print all combos of sofs for one exp\n",
    "            for sf1 in sofs:\n",
    "                for sf2 in sofs:\n",
    "                    h.extend(grab_run_stats(model, seed, exp, sf1, sf2, half=half))\n",
    "        else: # runs for only one specific sof and exp\n",
    "            h.extend(grab_run_stats(model, seed, exp, sof1, sof2, half=half))\n",
    "    return pd.DataFrame.from_dict(h)\n",
    "\n",
    "def print_run2_stats(run):\n",
    "    result = []\n",
    "    \n",
    "    result.append(f'sof_a1_label: {run[\"sof_a1_label\"]}')\n",
    "    result.append(f'sof_a2_label: {run[\"sof_a2_label\"]}')\n",
    "    result.append(f'a1_value: {run[\"a1_value\"]}')\n",
    "    result.append(f'a2_value: {run[\"a2_value\"]}')\n",
    "    result.append(f'a1_utility: {run[\"a1_function\"]}')\n",
    "    result.append(f'a2_utility: {run[\"a2_function\"]}')\n",
    "    result.append(f'a1_alignment: {run[\"a1_sof_alignment\"]}')\n",
    "    result.append(f'a2_alignment: {run[\"a2_sof_alignment\"]}')\n",
    "    \n",
    "    result.append('')\n",
    "    result.append(f'a1_deception_count: {run[\"a1_deception_count\"]}')\n",
    "    result.append(f'a1_deception_count_avg: {run[\"a1_deception_count_avg\"]}')\n",
    "    result.append(f'a1_deception_score_avg: {run[\"a1_deception_score_avg\"]}')\n",
    "    result.append(f'a2_deception_count: {run[\"a2_deception_count\"]}')\n",
    "    result.append(f'a2_deception_count_avg: {run[\"a2_deception_count_avg\"]}')\n",
    "    result.append(f'a2_deception_score_avg: {run[\"a2_deception_score_avg\"]}')\n",
    "    \n",
    "    result.append('')\n",
    "    result.append(f'a1_falsehood_count: {run[\"a1_falsehood_count\"]}')\n",
    "    result.append(f'a1_falsehood_count_avg: {run[\"a1_falsehood_count_avg\"]}')\n",
    "    result.append(f'a1_falsehood_score_avg: {run[\"a1_falsehood_score_avg\"]}')\n",
    "    result.append(f'a2_falsehood_count: {run[\"a2_falsehood_count\"]}')\n",
    "    result.append(f'a2_falsehood_count_avg: {run[\"a2_falsehood_count_avg\"]}')\n",
    "    result.append(f'a2_falsehood_score_avg: {run[\"a2_falsehood_score_avg\"]}')\n",
    "    \n",
    "    result.append('')\n",
    "    result.append(f'a1_pareto_deception: {run[\"a1_pareto_deception\"]}')\n",
    "    result.append(f'a2_pareto_deception: {run[\"a2_pareto_deception\"]}')\n",
    "    result.append(f'a1_deceptive_regret_beliefs_convo_lvl: {run[\"a1_deceptive_regret_beliefs_convo_lvl\"]}')\n",
    "    result.append(f'a2_deceptive_regret_beliefs_convo_lvl: {run[\"a2_deceptive_regret_beliefs_convo_lvl\"]}')\n",
    "    result.append(f'a1_point_guesses: {run[\"a1_point_guesses\"]}')\n",
    "    result.append(f'a2_point_guesses: {run[\"a2_point_guesses\"]}')\n",
    "    \n",
    "    result.append('')\n",
    "    result.append(f'valid_u_post_u_prior: {run[\"valid_u_post_u_prior\"]}')\n",
    "    result.append(f'a1_u_post_u_prior_avg: {run[\"a1_u_post_u_prior_avg\"]}')\n",
    "    result.append(f'a1_v_post_v_prior_avg: {run[\"a1_v_post_v_prior_avg\"]}')\n",
    "    result.append(f'a1_a_post_a_prior_avg: {run[\"a1_a_post_a_prior_avg\"]}')\n",
    "    result.append(f'a2_u_post_u_prior_avg: {run[\"a2_u_post_u_prior_avg\"]}')\n",
    "    result.append(f'a2_v_post_v_prior_avg: {run[\"a2_v_post_v_prior_avg\"]}')\n",
    "    result.append(f'a2_a_post_a_prior_avg: {run[\"a2_a_post_a_prior_avg\"]}')\n",
    "    \n",
    "    result.append('')\n",
    "    result.append(f'index: {run[\"index\"]}')\n",
    "    result.append(f'a1_vals: {[run[\"a1_book_val\"], run[\"a1_hat_val\"], run[\"a1_ball_val\"]]}')\n",
    "    result.append(f'a2_vals: {[run[\"a2_book_val\"], run[\"a2_hat_val\"], run[\"a2_ball_val\"]]}')\n",
    "    \n",
    "    result.append('')\n",
    "    result.append(run['conversation'])\n",
    "    \n",
    "    return '\\n'.join(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modify with dataset to grab\n",
    "#df1 = grab_exp_run_stats('gpt-3.5-turbo', '45')\n",
    "\n",
    "\n",
    "# TOM no deception\n",
    "# df1 = grab_exp_run_stats('gpt-3.5-turbo', '50')\n",
    "# df2 = grab_exp_run_stats('Llama-3-70B-Instruct', '50')\n",
    "# df1 = pd.concat([df1, df2], axis=0)\n",
    "\n",
    "df1 = grab_exp_run_stats('gpt-3.5-turbo', '72')\n",
    "df1['model'] = 'gpt-3.5-turbo'\n",
    "df2 = grab_exp_run_stats('Llama-3.1-70B-Instruct', '72')\n",
    "df2['model'] = 'Llama-3.1-70B-Instruct'\n",
    "df3 = grab_exp_run_stats('Llama-3.1-8B-Instruct', '72')\n",
    "df3['model'] = 'Llama-3.1-8B-Instruct'\n",
    "df4 = grab_exp_run_stats('mistral-instruct', '72')\n",
    "df4['model'] = 'mistral-instruct'\n",
    "df5 = grab_exp_run_stats('mixtral-instruct', '72')\n",
    "df5['model'] = 'mixtral-instruct'\n",
    "df1 = pd.concat([df1, df2, df3, df4, df5], axis=0)\n",
    "#df1 = df1[df1['sof_a1_label'] == 'max']\n",
    "def preprocess(df):\n",
    "    df['sof_a1_label'] = df['sof_a1_label'].replace({'_': ''}, regex=True)\n",
    "    df['sof_a2_label'] = df['sof_a2_label'].replace({'_': ''}, regex=True)\n",
    "    df['a1_taxicabs_mean_mean'] = (df['a1_taxicabs_mean'] +  df['a1_third_person_taxicabs_mean']) / 2\n",
    "    df['a2_taxicabs_mean_mean'] = (df['a2_taxicabs_mean'] +  df['a2_third_person_taxicabs_mean']) / 2\n",
    "\n",
    "preprocess(df1)\n",
    "print(df1.columns)\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_half = grab_exp_run_stats('Llama-3.1-70B-Instruct', '73', half=True)\n",
    "df_half['model'] = 'Llama-3.1-70B-Instruct'\n",
    "df_half2 = grab_exp_run_stats('gpt-3.5-turbo', '73', half=True)\n",
    "df_half2['model'] = 'gpt-3.5-turbo'\n",
    "df_half = pd.concat([df_half, df_half2], axis=0)\n",
    "preprocess(df_half)\n",
    "print(df_half.columns)\n",
    "df_half"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_half2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_half['half_agent']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Blacklist certain columns from dropdown selection for readability\n",
    "# remove columns from blacklist if you think they're helpful\n",
    "# columns will still be outputted if point is clicked\n",
    "blacklist = [\n",
    "    'a1_books', 'a1_hats', 'a1_balls', \n",
    "    'a2_books', 'a2_hats', 'a2_balls', \n",
    "    'conversation', 'valid', 'valid_guess', \n",
    "    'decided_no_agreement', 'exceeded_rounds',\n",
    "    'index', 'prompt', 'chain_of_thought',\n",
    "    'a1_book_val', 'a1_hat_val', 'a1_ball_val', \n",
    "    'a2_book_val', 'a2_hat_val','a2_ball_val',\n",
    "    'deception_list', 'falsehood_list',\n",
    "    'running_cost_for_iteration', 'agent_thoughts',\n",
    "    'a1_point_guesses', 'a2_point_guesses', \n",
    "    'valid_u_post_u_prior', 'u_post_u_prior_list'\n",
    "    ]\n",
    "metric_selection = [metric for metric in df1.columns if metric not in blacklist]\n",
    "metric_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "styles = {\n",
    "    'pre': {\n",
    "        'border': 'thin lightgrey solid',\n",
    "        'backgroundColor': '#FFFFFF',\n",
    "        'overflowX': 'scroll'\n",
    "    }\n",
    "}\n",
    "\n",
    "app.layout = html.Div([\n",
    "    html.Div([\n",
    "            dcc.Markdown(\"\"\"\n",
    "                **x-axis metric**\n",
    "            \"\"\"),\n",
    "            dcc.Dropdown(\n",
    "                metric_selection,\n",
    "                'a1_pareto_deception',\n",
    "                id='crossfilter-xaxis-column',\n",
    "            )\n",
    "        ],\n",
    "        style={'width': '49%', 'display': 'inline-block'}),\n",
    "    \n",
    "    html.Div([\n",
    "            dcc.Markdown(\"\"\"\n",
    "                **y-axis metric**\n",
    "            \"\"\"),\n",
    "            dcc.Dropdown(\n",
    "                metric_selection,\n",
    "                'a1_sof_alignment',\n",
    "                id='crossfilter-yaxis-column',\n",
    "            )\n",
    "        ],\n",
    "        style={'width': '49%', 'display': 'inline-block'}),\n",
    "\n",
    "    dcc.Graph(\n",
    "        id='graph'\n",
    "        #figure=fig\n",
    "    ),\n",
    "    \n",
    "    html.Div([\n",
    "            dcc.Markdown(\"\"\"\n",
    "                **color metric**\n",
    "            \"\"\"),\n",
    "            dcc.Dropdown(\n",
    "                metric_selection,\n",
    "                'exp_num',\n",
    "                id='crossfilter-color-column',\n",
    "            )\n",
    "        ],\n",
    "        style={'width': '49%', 'display': 'inline-block'}),\n",
    "\n",
    "    html.Div(className='row', children=[\n",
    "        html.Div([\n",
    "            dcc.Markdown(\"\"\"\n",
    "                **Click Data**\n",
    "\n",
    "                Click on points in the graph.\n",
    "            \"\"\"),\n",
    "            html.Pre(id='click-data', style=styles['pre']),\n",
    "        ], className='three columns'),\n",
    "    ])\n",
    "])\n",
    "\n",
    "@callback(\n",
    "    Output('graph', 'figure'),\n",
    "    Input('crossfilter-xaxis-column', 'value'),\n",
    "    Input('crossfilter-yaxis-column', 'value'),\n",
    "    Input('crossfilter-color-column', 'value'))\n",
    "def update_graph(xaxis_column_name, yaxis_column_name, color_column_name):\n",
    "    fig1 = px.scatter(df1, x=xaxis_column_name, y=yaxis_column_name, color=color_column_name, opacity=0.5, trendline='ols', custom_data=df1.columns)\n",
    "    results = px.get_trendline_results(fig1)\n",
    "    newnames = {results.iloc[i][color_column_name]:results.iloc[i][color_column_name] + ': ' + str(results['px_fit_results'][i].rsquared) for i in range(len(results))}\n",
    "    \n",
    "    fig = px.scatter(df1, x=xaxis_column_name, y=yaxis_column_name, color=color_column_name, opacity=0.5, custom_data=df1.columns)\n",
    "    fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                        legendgroup = newnames[t.name],\n",
    "                                        hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                        )\n",
    "                    )\n",
    "    fig.show()\n",
    "    fig.update_layout(clickmode='event+select')\n",
    "    fig.update_traces(marker=dict(size=1))\n",
    "    return fig\n",
    "\n",
    "\n",
    "@callback(\n",
    "    Output('click-data', 'children'),\n",
    "    Input('graph', 'clickData'))\n",
    "def display_click_data(clickData):\n",
    "    if clickData:\n",
    "        data = clickData[\"points\"][0][\"customdata\"]\n",
    "        data_dict = {df1.columns[i]: data[i] for i in range(len(data))}\n",
    "        return print_run2_stats(data_dict)\n",
    "    return json.dumps(clickData, indent=2)\n",
    "\n",
    "# Note: if server is already running, kernel might need to be restarted more than once\n",
    "# http://127.0.0.1:8371/\n",
    "app.run_server(host='127.0.0.1', port='8371', debug=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['sof'] = df1.sof_a1_label + '_' + df1.sof_a2_label\n",
    "df_antideception = df1[(df1['a1_deceptive_regret_beliefs_convo_lvl'] < 0)]\n",
    "df_deception = df1[(df1['a1_deceptive_regret_beliefs_convo_lvl'] > 0)]\n",
    "df_none = df1[(df1['a1_deceptive_regret_beliefs_convo_lvl'] == 0)]\n",
    "\n",
    "df_antideception = df_antideception.sort_values(by=['exp_num'])\n",
    "df_deception = df_deception.sort_values(by=['exp_num'])\n",
    "df_none = df_none.sort_values(by=['exp_num'])\n",
    "df_deception"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rename_exp(fig):\n",
    "    newnames = dict(exp0='shared points, no deception', exp1='no deception', exp2='deception', exp3='deception, full persuasion taxonomy', exp4='deception, TOM, full persuasion taxonomy', exp5='no deception, full persuasion taxonomy', exp6='deception, reduced persuasion taxonomy', exp7='deception, TOM, reduced', exp8='no deception, reduced')\n",
    "    fig.for_each_trace(lambda t: t.update(name = newnames[t.name],\n",
    "                                        legendgroup = newnames[t.name],\n",
    "                                        hovertemplate = t.hovertemplate.replace(t.name, newnames[t.name])\n",
    "                                        )\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.histogram(df_deception, x='sof', color='exp_num', title='a1 deceptive regret > 0 (indicator Agent 1 is deceptive)').update_xaxes(categoryorder='category ascending')\n",
    "rename_exp(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_antideception, x='sof', color='exp_num', title='a1 deceptive regret < 0 (indicator Agent 1 is altruistic)').update_xaxes(categoryorder='category ascending')\n",
    "rename_exp(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_none, x='sof', color='exp_num', title='a1 deceptive regret == 0 (indicator Agent 1 is neither)').update_xaxes(categoryorder='category ascending')\n",
    "rename_exp(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antideception = df_antideception.sort_values(by=['a1_sof_alignment'])\n",
    "df_deception = df_deception.sort_values(by=['a1_sof_alignment'])\n",
    "df_none = df_none.sort_values(by=['a1_sof_alignment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_deception, x='sof', color='a1_sof_alignment', title='a1 deceptive regret > 0', color_continuous_scale=px.colors.sequential.Turbo).update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig = px.histogram(df_deception, x='sof', color='a1_sof_alignment', title='a1 deceptive regret > 0 (indicator Agent 1 is deceptive)', color_discrete_sequence=[px.colors.sequential.Turbo[i // 18] for i in range(len(px.colors.sequential.Turbo)*18)]).update_xaxes(categoryorder='category ascending')\n",
    "#fig.update_traces(showlegend=False)\n",
    "#fig.add_trace(go.Bar(x=df_deception['sof'], y=df_deception['a2_sof_alignment'], name='a2 deceptive regret > 0', marker=dict(color=px.colors.sequential.Turbo, coloraxis=\"coloraxis\")))\n",
    "#fig.update_layout(coloraxis=dict(colorscale='Bluered_r'), showlegend=True)\n",
    "#fig.update_layout(coloraxis_showscale=True)\n",
    "# fig.update_layout(coloraxis_colorbar=dict(\n",
    "#     title=\"Number of Bills per Cell\",\n",
    "#     thicknessmode=\"pixels\", thickness=50,\n",
    "#     lenmode=\"pixels\", len=200,\n",
    "#     yanchor=\"top\", y=1,\n",
    "#     ticks=\"outside\", ticksuffix=\" bills\",\n",
    "#     dtick=5\n",
    "# ))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_antideception, x='sof', color='a1_sof_alignment', title='a1 deceptive regret < 0 (indicator Agent 1 is altruistic)', color_discrete_sequence=[px.colors.sequential.Turbo[i // 24] for i in range(len(px.colors.sequential.Turbo)*24)]).update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_none, x='sof', color='a1_sof_alignment', title='a1 deceptive regret == 0 (indicator agent is neither)', color_discrete_sequence=[px.colors.sequential.Turbo[i // 7] for i in range(len(px.colors.sequential.Turbo)*7)]).update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antideception_a1 = df1[(df1['a1_deceptive_regret_beliefs_convo_lvl'] < 0)]\n",
    "df_deception_a1 = df1[(df1['a1_deceptive_regret_beliefs_convo_lvl'] > 0)]\n",
    "df_antideception_a2 = df1[(df1['a2_deceptive_regret_beliefs_convo_lvl'] < 0)]\n",
    "df_deception_a2 = df1[(df1['a2_deceptive_regret_beliefs_convo_lvl'] > 0)]\n",
    "df_none_a1 = df1[(df1['a1_deceptive_regret_beliefs_convo_lvl'] == 0)]\n",
    "df_none_a2 = df1[(df1['a2_deceptive_regret_beliefs_convo_lvl'] == 0)]\n",
    "\n",
    "df_antideception_a1['sof_individual'] = df_antideception_a1['sof_a1_label']\n",
    "df_deception_a1['sof_individual'] = df_deception_a1['sof_a1_label']\n",
    "df_antideception_a1['sof_alignment'] = df_antideception_a1['a1_sof_alignment']\n",
    "df_deception_a1['sof_alignment'] = df_deception_a1['a1_sof_alignment']\n",
    "df_none_a1['sof_individual'] = df_none_a1['sof_a1_label']\n",
    "df_none_a1['sof_alignment'] = df_none_a1['a1_sof_alignment']\n",
    "\n",
    "df_antideception_a2['sof_individual'] = df_antideception_a2['sof_a2_label']\n",
    "df_deception_a2['sof_individual'] = df_deception_a2['sof_a2_label']\n",
    "df_antideception_a2['sof_alignment'] = df_antideception_a2['a2_sof_alignment']\n",
    "df_deception_a2['sof_alignment'] = df_deception_a2['a2_sof_alignment']\n",
    "df_none_a2['sof_individual'] = df_none_a2['sof_a2_label']\n",
    "df_none_a2['sof_alignment'] = df_none_a2['a2_sof_alignment']\n",
    "\n",
    "df_deception_combined = pd.concat([df_deception_a1, df_deception_a2], axis=0)\n",
    "df_antideception_combined = pd.concat([df_antideception_a1, df_antideception_a2], axis=0)\n",
    "df_none_combined = pd.concat([df_none_a1, df_none_a2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antideception_combined = df_antideception_combined.sort_values(by=['exp_num'])\n",
    "df_deception_combined = df_deception_combined.sort_values(by=['exp_num'])\n",
    "df_none_combined = df_none_combined.sort_values(by=['exp_num'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_deception_combined, x='sof_individual', color='exp_num', title='a1 or a2 deceptive regret > 0 (indicator agent is deceptive)').update_xaxes(categoryorder='category ascending')\n",
    "rename_exp(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_antideception_combined, x='sof_individual', color='exp_num', title='a1 or a2 deceptive regret < 0 (indicator agent is altruistic)').update_xaxes(categoryorder='category ascending')\n",
    "rename_exp(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_none_combined, x='sof_individual', color='exp_num', title='a1 or a2 deceptive regret == 0 (indicator agent is neither)').update_xaxes(categoryorder='category ascending')\n",
    "rename_exp(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_deception_combined = df_deception_combined.sort_values(by=['sof_alignment'])\n",
    "df_antideception_combined = df_antideception_combined.sort_values(by=['sof_alignment'])\n",
    "df_none_combined = df_none_combined.sort_values(by=['sof_alignment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.bar(df_deception_combined, x='sof_individual', color='sof_alignment', title='a1 or a2 deceptive regret > 0 (indicator agent is deceptive)', color_continuous_scale=px.colors.sequential.Turbo).update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_deception_combined, x='sof_individual', color='sof_alignment', title='a1 or a2 deceptive regret > 0 (indicator agent is deceptive)', color_discrete_sequence=[px.colors.sequential.Turbo[i // 26] for i in range(len(px.colors.sequential.Turbo)*26)]).update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_antideception_combined, x='sof_individual', color='sof_alignment', title='a1 or a2 deceptive regret < 0 (indicator agent is altruistic)', color_discrete_sequence=[px.colors.sequential.Turbo[i // 33] for i in range(len(px.colors.sequential.Turbo)*33)]).update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_none_combined, x='sof_individual', color='sof_alignment', title='a1 or a2 deceptive regret == 0 (indicator agent is neither)', color_discrete_sequence=[px.colors.sequential.Turbo[i // 11] for i in range(len(px.colors.sequential.Turbo)*11)][:-22] + [px.colors.sequential.Turbo[-3]]*6 + [px.colors.sequential.Turbo[-3]]*5 + [px.colors.sequential.Turbo[-2]]*13 + [px.colors.sequential.Turbo[-1]]).update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(df1, x=\"sof_a1_label\", y=\"sof_a2_label\", z=\"a1_sof_alignment\", histfunc=\"avg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(df1, x=\"sof_a1_label\", y=\"sof_a2_label\", z=\"a2_sof_alignment\", histfunc=\"avg\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(df1, x=\"sof_a1_label\", y=\"sof_a2_label\", z=\"a1_deceptive_regret_beliefs_convo_lvl\", color_continuous_scale=px.colors.sequential.Blues, histfunc=\"avg\", text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.density_heatmap(df1, x=\"sof_a1_label\", y=\"sof_a2_label\", z=\"a2_deceptive_regret_beliefs_convo_lvl\", color_continuous_scale=px.colors.sequential.Blues, histfunc=\"avg\", text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='model', color='sof_alignment', title='a1 or a2 deceptive regret == 0 (indicator agent is neither)', color_discrete_sequence=[px.colors.sequential.Turbo[i // 11] for i in range(len(px.colors.sequential.Turbo)*11)][:-22] + [px.colors.sequential.Turbo[-3]]*6 + [px.colors.sequential.Turbo[-3]]*5 + [px.colors.sequential.Turbo[-2]]*13 + [px.colors.sequential.Turbo[-1]]).update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_deception(column_name):\n",
    "    def helper(row):\n",
    "        if row[column_name] < 0:\n",
    "            return 'Not Deceptive'\n",
    "        if row[column_name] > 0:\n",
    "            return 'Deceptive'\n",
    "        if row[column_name] == 0:\n",
    "            return 'Neither'        \n",
    "    return helper\n",
    "df1_deception_label1 = df1.copy(deep=True)\n",
    "df1_deception_label2 = df1.copy(deep=True)\n",
    "df1_deception_label1['deception_posterior_label'] = df1.apply(label_deception('a1_deceptive_regret_beliefs_convo_lvl'), axis=1)\n",
    "df1_deception_label2['deception_posterior_label'] = df1.apply(label_deception('a2_deceptive_regret_beliefs_convo_lvl'), axis=1)\n",
    "\n",
    "df1_deception_label = pd.concat([df1_deception_label1, df1_deception_label2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1_deception_label, x='deception_posterior_label', color='model', text_auto=True,title='Deceptive Regret on Posterior by Model', barmode='group').update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_antideception_combined['deception_posterior_label'] = 'Not Deceptive'\n",
    "df_deception_combined['deception_posterior_label'] = 'Deceptive'\n",
    "df_none_combined['deception_posterior_label'] = 'Neither'\n",
    "df_sof_combined = pd.concat([df_deception_combined, df_antideception_combined, df_none_combined], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_sof_combined, x='deception_posterior_label', color='sof_individual', text_auto=True, title='Deceptive Regret on Posterior by SOF', barmode='group').update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1_deception_label, x='deception_posterior_label', color='exp_num', text_auto=True, title='Deceptive Regret on Posterior by Experiment', barmode='group').update_xaxes(categoryorder='category ascending')\n",
    "rename_exp(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a1_taxicabs_mean', color='model', title='a1 taxicabs mean', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a2_taxicabs_mean', color='model', title='a2 taxicabs mean', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a1_third_person_taxicabs_mean', color='model', title='a1 third person taxicabs mean', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a2_third_person_taxicabs_mean', color='model', title='a2 third person taxicabs mean', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a1_taxicabs_mean_mean', color='model', title='a1 taxicabs mean mean', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a2_taxicabs_mean_mean', color='model', title='a2 taxicabs mean mean', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a1_taxicabs_last', color='model', title='a1 taxicabs last', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a2_taxicabs_last', color='model', title='a2 taxicabs last', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a1_third_person_taxicabs_last', color='model', title='a1 third person taxicabs last', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a2_third_person_taxicabs_last', color='model', title='a2 third person taxicabs last', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a1_deceptive_regret_beliefs_convo_lvl', color='model', title='a1 deceptive regret', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a2_deceptive_regret_beliefs_convo_lvl', color='model', title='a2 deceptive regret', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1, x='a2_deceptive_regret_beliefs_convo_lvl', color='exp_num', title='a1 deceptive regret', text_auto=True)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_deception_avg(column_name):\n",
    "    avg = df1[column_name].mean()\n",
    "    def helper(row):\n",
    "        if row[column_name] < avg:\n",
    "            return 'Not Deceptive'\n",
    "        if row[column_name] > avg:\n",
    "            return 'Deceptive'\n",
    "        if row[column_name] == avg:\n",
    "            return 'Neither'        \n",
    "    return helper\n",
    "df1_ground_deception_label1 = df1.copy(deep=True)\n",
    "df1_ground_deception_label2 = df1.copy(deep=True)\n",
    "df1_ground_deception_label1['deception_posterior_label'] = df1.apply(label_deception_avg('a1_third_person_taxicabs_mean'), axis=1)\n",
    "df1_ground_deception_label2['deception_posterior_label'] = df1.apply(label_deception_avg('a2_third_person_taxicabs_mean'), axis=1)\n",
    "\n",
    "df1_ground_deception_label = pd.concat([df1_ground_deception_label1, df1_ground_deception_label2], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1_ground_deception_label, x='deception_posterior_label', color='model', text_auto=True,title='Deceptive Regret on Ground Truth by Model', barmode='group').update_xaxes(categoryorder='category ascending')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df1_ground_deception_label, x='deception_posterior_label', color='exp_num', text_auto=True, title='Deceptive Regret on Posterior by Experiment', barmode='group').update_xaxes(categoryorder='category ascending')\n",
    "rename_exp(fig)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_half, x='a1_deceptive_regret_beliefs_convo_lvl', color='half_agent', text_auto=True, title='a1 deceptive regret on posterior  (Llama-3.1-70B-Instruct + 1/3 gpt-3.5.turbo)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_half, x='a2_deceptive_regret_beliefs_convo_lvl', text_auto=True, color='half_agent', title='a2 deceptive regret on posterior  (Llama-3.1-70B-Instruct + 1/3 gpt-3.5-turbo)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_half, x='a1_sof_alignment', color='half_agent', text_auto=True, title='a1 alignment distribution (Llama-3.1-70B-Instruct + 1/3 gpt-3.5-turbo)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_half, x='a2_sof_alignment', color='half_agent', text_auto=True, title='a2 alignment distribution (Llama-3.1-70B-Instruct + 1/3 gpt-3.5-turbo)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_half, x='a1_taxicabs_mean', color='half_agent', text_auto=True, title='a1 taxicabs mean  (Llama-3.1-70B-Instruct + 1/3 gpt-3.5-turbo)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_half, x='a2_taxicabs_mean', color='half_agent', text_auto=True, title='a2 taxicabs mean (Llama-3.1-70B-Instruct + 1/3 gpt-3.5-turbo)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_half, x='a1_third_person_taxicabs_mean', color='half_agent', text_auto=True, title='a1 third person taxicabs mean (Llama-3.1-70B-Instruct + 1/3 gpt-3.5-turbo)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = px.histogram(df_half, x='a2_third_person_taxicabs_mean', color='half_agent', text_auto=True, title='a2 third person taxicabs mean (Llama-3.1-70B-Instruct + 1/3 gpt-3.5-turbo)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
